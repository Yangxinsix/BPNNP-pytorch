{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3d7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from torch import nn\n",
    "from ase.io import read, write\n",
    "import asap3\n",
    "from ase.db import connect\n",
    "from torch_scatter import scatter_min\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "from ase.data import atomic_numbers\n",
    "from torch_scatter import scatter_min, scatter_add\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df4691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import math\n",
    "import numpy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90720c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this block is really tricky!\n",
    "## Get dataset\n",
    "\n",
    "from ase.db import connect\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "def ase_properties(atoms):\n",
    "    \"\"\"Guess dataset format from an ASE atoms\"\"\"\n",
    "    atoms_prop = {\n",
    "        'elems': {'dtype':  'int32', 'shape': [None]},\n",
    "        'coord': {'dtype':  'float', 'shape': [None, 3]}}\n",
    "\n",
    "    if atoms.pbc.any():\n",
    "        atoms_prop['cell'] = {'dtype': 'float', 'shape': [3, 3]}\n",
    "\n",
    "    try:\n",
    "        atoms.get_potential_energy()\n",
    "        atoms_prop['energy'] = {'dtype': 'float', 'shape': []}\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        atoms.get_forces()\n",
    "        atoms_prop['forces'] = {'dtype': 'float', 'shape': [None, 3]}\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return atoms_prop\n",
    "\n",
    "def ase_data_reader(atoms, atoms_prop):\n",
    "    atoms_data = {\n",
    "        'numbers': torch.tensor(atoms.get_global_number_of_atoms()),\n",
    "        'elems': torch.tensor(atoms.numbers),\n",
    "        'coord': torch.tensor(atoms.positions, dtype=torch.float),\n",
    "    }\n",
    "    if 'cell' in atoms_prop:\n",
    "        atoms_data['cell'] = torch.tensor(atoms.cell[:], dtype=torch.float)\n",
    "\n",
    "    if 'energy' in atoms_prop:\n",
    "        atoms_data['energy'] = torch.tensor(atoms.get_potential_energy(), dtype=torch.float)\n",
    "\n",
    "    if 'forces' in atoms_prop:\n",
    "        atoms_data['forces'] = torch.tensor(atoms.get_forces(), dtype=torch.float)\n",
    "    \n",
    "    return atoms_data\n",
    "\n",
    "class AseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ase_db, cutoff, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if isinstance(ase_db, str):\n",
    "            self.db = connect(ase_db)\n",
    "        else:\n",
    "            self.db = ase_db\n",
    "        \n",
    "        self.cutoff = cutoff\n",
    "        self.atoms_prop = ase_properties(self.db[1].toatoms())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        atoms = self.db[idx+1].toatoms()    # ase database indexing from 1 \n",
    "        atoms_data = ase_data_reader(atoms, self.atoms_prop)\n",
    "        \n",
    "        return atoms_data\n",
    "\n",
    "def cat_tensors(tensors: List[torch.Tensor]):\n",
    "    if tensors[0].shape:\n",
    "        return torch.cat(tensors)\n",
    "    return torch.stack(tensors)\n",
    "\n",
    "def collate_atomsdata(atoms_data: List[dict], pin_memory=True):\n",
    "    # convert from list of dicts to dict of lists\n",
    "    dict_of_lists = {k: [dic[k] for dic in atoms_data] for k in atoms_data[0]}\n",
    "    if pin_memory:\n",
    "        pin = lambda x: x.pin_memory()\n",
    "    else:\n",
    "        pin = lambda x: x\n",
    "        \n",
    "    collated = {k: cat_tensors(v) for k, v in dict_of_lists.items()}\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67b4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "import torch\n",
    "from torch_scatter import scatter_min, scatter_add\n",
    "from torch import nn\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "from ase.data import atomic_numbers\n",
    "\n",
    "class BatchNeighborList:\n",
    "    def __init__(self, cutoff, compute_force=True):\n",
    "        self.cutoff = cutoff\n",
    "        self.compute_force = compute_force\n",
    "        disp_mat = torch.zeros([3, 3, 3, 3]).long()\n",
    "        helper_arr = torch.LongTensor([-1, 0, 1])\n",
    "        disp_mat[:, :, :, 0] = torch.reshape(helper_arr, (3, 1, 1))\n",
    "        disp_mat[:, :, :, 1] = torch.reshape(helper_arr, (1, 3, 1))\n",
    "        disp_mat[:, :, :, 2] = torch.reshape(helper_arr, (1, 1, 3))\n",
    "        self.disp_mat = disp_mat.reshape(27, 3)\n",
    "        \n",
    "    def __call__(self, tensors):\n",
    "        # get batch cell, coordinates information and \n",
    "        # get atoms' image indices and real indices (where is the atom in the image)\n",
    "        tensors['coord'].requires_grad_(self.compute_force)\n",
    "        atom_cell = tensors['cell']\n",
    "        atom_apos = tensors['coord']\n",
    "        atom_counts = tensors['numbers']\n",
    "        atom_image_ind = torch.arange(atom_counts.shape[0], device=tensors['coord'].device).repeat_interleave(atom_counts)\n",
    "        image_atom_counts = torch.zeros_like(atom_counts)\n",
    "        image_atom_counts[1:] = atom_counts[:-1]\n",
    "        image_atom_counts = torch.cumsum(image_atom_counts, dim=0)\n",
    "        atom_real_ind = image_atom_counts[atom_image_ind]\n",
    "        \n",
    "        # define cell parameter, cell shape, cell size\n",
    "        c_len = torch.norm(atom_cell, dim=1).view(-1, 3)\n",
    "        c_pos_shap = torch.div(c_len, self.cutoff, rounding_mode='floor').int()\n",
    "        rc = c_len / c_pos_shap\n",
    "        \n",
    "        # define cell positions and cell indices\n",
    "        cell_cpos = torch.ones(tuple(torch.max(c_pos_shap, dim=0)[0]), device=tensors['coord'].device)\n",
    "        cell_cpos = cell_cpos.repeat(c_pos_shap.shape[0], 1, 1, 1)\n",
    "        cind = torch.nonzero(cell_cpos)\n",
    "        cell_cpos = cind[torch.all(cind[:, 1:] < c_pos_shap[cind[:, 0]], dim=1)]   # I'm incredible!!!\n",
    "        cell_image_ind, cell_cpos = cell_cpos[:, 0], cell_cpos[:, 1:]\n",
    "        \n",
    "        # this matrix is used to calculate cell indices given cell postion vectors\n",
    "        count_mat = torch.ones_like(c_pos_shap)\n",
    "        count_mat[:, 0] = c_pos_shap[:, 1] * c_pos_shap[:, 2]\n",
    "        count_mat[:, 1] = c_pos_shap[:, 2]\n",
    "        \n",
    "        # count how many cells there are for each images\n",
    "        cell_counts = torch.unique_consecutive(cell_image_ind, return_counts=True)[1]\n",
    "        image_cell_counts = torch.zeros_like(cell_counts)\n",
    "        image_cell_counts[1:] = cell_counts[:-1]\n",
    "        image_cell_counts = torch.cumsum(image_cell_counts, dim=0)\n",
    "        \n",
    "        # locate the positions of atoms in which cell\n",
    "        atom_gind = torch.arange(atom_apos.size(0), device=tensors['coord'].device) + 1\n",
    "        atom_cpos = torch.div(atom_apos, rc[atom_image_ind], rounding_mode='floor').long()\n",
    "        atom_cind = torch.squeeze(torch.sum(atom_cpos * count_mat[atom_image_ind], dim=1))\n",
    "        atom_cind += image_cell_counts[atom_image_ind]\n",
    "        \n",
    "        # get cell atom list\n",
    "        atom_cind_sort, atom_cind_args = torch.sort(atom_cind, dim = 0, stable = True)\n",
    "        cell_rind_min = scatter_min(atom_gind, atom_cind_sort)[0]\n",
    "        atom_rind = atom_gind - torch.take(cell_rind_min, atom_cind_sort)\n",
    "        atom_rpos = torch.stack((atom_cind_sort, atom_rind), dim = 1)\n",
    "        cell_alsshap = torch.Size([cell_cpos.size(0), torch.max(atom_rind) + 1])\n",
    "        cell_alst = torch.zeros(cell_alsshap, device=tensors['coord'].device).long()\n",
    "        cell_alst = cell_alst.index_put(tuple(atom_rpos.t()), atom_cind_args + 1)\n",
    "        \n",
    "        # get cell neighbors and shifts to accurately calculate distance between atoms\n",
    "        disp_mat = self.disp_mat.to(tensors['coord'].device)\n",
    "        cell_npos = torch.unsqueeze(cell_cpos, 1) + disp_mat\n",
    "        cell_nind = (cell_npos + c_pos_shap[cell_image_ind].unsqueeze(dim=1)) % c_pos_shap[cell_image_ind].unsqueeze(dim=1)\n",
    "        cell_nind = torch.sum(cell_nind * count_mat[cell_image_ind].unsqueeze(dim=1), dim=-1)\n",
    "        \n",
    "        mask_1 = cell_npos < 0\n",
    "        mask_2 = torch.ge(cell_npos, c_pos_shap[cell_image_ind].unsqueeze(dim=1))\n",
    "        cell_nshift = torch.zeros_like(cell_npos).masked_fill_(mask_1, -1).masked_fill_(mask_2, 1)\n",
    "        cell_nshift = cell_nshift * c_len[cell_image_ind].unsqueeze(dim=1)\n",
    "        \n",
    "        # get atoms' neighbor cells and atoms in these cells\n",
    "        atom_cnind = cell_nind[atom_cind].squeeze() + image_cell_counts[atom_image_ind].unsqueeze(dim=-1)\n",
    "        atom_cnshift = cell_nshift[atom_cind]\n",
    "        atom_nind = cell_alst[atom_cnind]\n",
    "        \n",
    "        # calculate distances between atoms in neighboring cells\n",
    "        pair_i_ind, neigh_ind, pair_j_ind = torch.where(atom_nind)\n",
    "        # notice!! pair_j indices should be took out from atom_nind[pair_i_ind, neigh_ind, pair_j_ind], and minus 1!!!\n",
    "        pair_j_ind = atom_nind[pair_i_ind, neigh_ind, pair_j_ind] - 1\n",
    "        pair_shift = atom_cnshift[pair_i_ind, neigh_ind]\n",
    "        pair_diff = (atom_apos[pair_j_ind] + pair_shift) - atom_apos[pair_i_ind]\n",
    "        pair_dist = torch.norm(pair_diff, dim = 1)\n",
    "        \n",
    "        # screen pairs with distance smaller than cutoff radius\n",
    "        ind_rc = torch.where((pair_dist > 0) & (pair_dist < self.cutoff))\n",
    "        pair_i_aind = pair_i_ind[ind_rc]\n",
    "        pair_j_aind = pair_j_ind[ind_rc]\n",
    "        diff = pair_diff[ind_rc]\n",
    "        dist = pair_dist[ind_rc]\n",
    "        tensors['atom_image_idx'] = atom_image_ind   # image index of each atom\n",
    "        tensors['pair_image_idx'] = atom_image_ind[pair_i_aind]   # image index of each pair\n",
    "        tensors['atom_i_idx'] = pair_i_aind         # the index of center atom i in all atoms of this batch\n",
    "        tensors['pair_i_idx'] = pair_i_aind - atom_real_ind[pair_i_aind]   # index of i in the image        \n",
    "        tensors['n_indices'] = pair_j_aind - atom_real_ind[pair_j_aind]   # index of j in the image\n",
    "        tensors['i_elems'] = tensors['elems'][pair_i_aind]   # element of pair i\n",
    "        tensors['j_elems'] = tensors['elems'][pair_j_aind]   # element of pair j\n",
    "        tensors['n_diff'] = diff                    # distance vector of R_j - R_i\n",
    "        tensors['n_dist'] = dist                    # distance between pair i and j\n",
    "        \n",
    "        return tensors\n",
    "    \n",
    "def G2_SF(tensors, j_elem, eta, R_s, R_c):\n",
    "    eta = eta.to(device=tensors['n_diff'].device)\n",
    "    R_s = R_s.to(device=tensors['n_diff'].device)\n",
    "    R_c = R_c.to(device=tensors['n_diff'].device)\n",
    "    atom_i_idx = tensors['atom_i_idx']\n",
    "    counts = tensors['counts']\n",
    "        \n",
    "    # find the right neighbors\n",
    "    j_mask = (tensors['j_elems'] == j_elem)\n",
    "    sfs = torch.zeros((counts.shape[0], R_c.shape[0]), device=tensors['n_diff'].device) \n",
    "    \n",
    "    # calculate symmetry function values\n",
    "    pair_dist = tensors['n_dist'][j_mask].unsqueeze(dim=-1)\n",
    "    pair_fc = 0.5 * (torch.cos(pair_dist * torch.pi / R_c) + 1)\n",
    "    pair_sfs = torch.exp(-eta * (pair_dist - R_s) ** 2) * pair_fc\n",
    "    sfs.index_add_(0, atom_i_idx[j_mask], pair_sfs)\n",
    "    \n",
    "    return sfs\n",
    "\n",
    "def G3_SF(tensors, j_elem, kappa, R_c):\n",
    "    kappa = kappa.to(device=tensors['n_diff'].device)\n",
    "    R_c = R_c.to(device=tensors['n_diff'].device)\n",
    "    atom_i_idx = tensors['atom_i_idx']\n",
    "    pair_j_idx = tensors['pair_j_idx']\n",
    "    counts = tensors['counts']\n",
    "        \n",
    "    # find the right neighbors\n",
    "    j_mask = (tensors['j_elems'] == j_elem)\n",
    "    sfs = torch.zeros((counts.shape[0], R_c.shape[0]), device=tensors['n_diff'].device)\n",
    "    \n",
    "    # calculate symmetry function values\n",
    "    pair_dist = tensors['n_dist'][j_mask].unsqueeze(dim=-1)\n",
    "    pair_fc = 0.5 * (torch.cos(pair_dist * torch.pi / R_c) + 1)\n",
    "    pair_sfs = torch.cos(kappa * pair_dist) * pair_fc\n",
    "    sfs.index_add_(0, atom_i_idx[j_mask], pair_sfs)\n",
    "    \n",
    "    return sfs\n",
    "\n",
    "def G5_SF(tensors, j_elem, k_elem, zeta, Lambda, eta, R_c):\n",
    "    zeta = zeta.to(device=tensors['n_diff'].device)\n",
    "    Lambda = Lambda.to(device=tensors['n_diff'].device)\n",
    "    eta = eta.to(device=tensors['n_diff'].device)\n",
    "    R_c = R_c.to(device=tensors['n_diff'].device)\n",
    "    diff = tensors['n_diff']\n",
    "    dist = tensors['n_dist']   \n",
    "    atom_i_idx = tensors['atom_i_idx']\n",
    "    counts = tensors['counts']\n",
    "    \n",
    "    j_mask = (tensors['j_elems'] == j_elem)\n",
    "    k_mask = (tensors['j_elems'] == k_elem)\n",
    "    \n",
    "    # get relative index of neighbors\n",
    "    atom_idx_j_masked, j_inv_idx, j_counts = torch.unique_consecutive(\n",
    "        atom_i_idx[j_mask], return_inverse=True, return_counts=True,\n",
    "    )\n",
    "    atom_idx_k_masked, k_inv_idx, k_counts = torch.unique_consecutive(\n",
    "        atom_i_idx[k_mask], return_inverse=True, return_counts=True,\n",
    "    )\n",
    "    \n",
    "    g_idx = torch.arange(j_inv_idx.shape[0], device=tensors['n_diff'].device)\n",
    "    idx_min, _ = scatter_min(g_idx, j_inv_idx)\n",
    "    j_ridx = g_idx - idx_min[j_inv_idx]\n",
    "\n",
    "    g_idx = torch.arange(k_inv_idx.shape[0], device=tensors['n_diff'].device)\n",
    "    idx_min, _ = scatter_min(g_idx, k_inv_idx)\n",
    "    k_ridx = g_idx - idx_min[k_inv_idx]\n",
    "    \n",
    "    # get the matrix of M * N * ..., \n",
    "    # where M is the number of center atoms, \n",
    "    # N is the maximum number of their j or k neighbors\n",
    "    diff_ij = torch.zeros((counts.shape[0], j_counts.max(), 3), device=tensors['n_diff'].device)\n",
    "    diff_ik = torch.zeros((counts.shape[0], k_counts.max(), 3), device=tensors['n_diff'].device)\n",
    "    dist_ij = torch.zeros((counts.shape[0], j_counts.max()), device=tensors['n_diff'].device)\n",
    "    dist_ik = torch.zeros((counts.shape[0], k_counts.max()), device=tensors['n_diff'].device)\n",
    "    \n",
    "    diff_ij[atom_i_idx[j_mask], j_ridx] = diff[j_mask]\n",
    "    diff_ik[atom_i_idx[k_mask], k_ridx] = diff[k_mask]\n",
    "    dist_ij[atom_i_idx[j_mask], j_ridx] = dist[j_mask]\n",
    "    dist_ik[atom_i_idx[k_mask], k_ridx] = dist[k_mask]\n",
    "    \n",
    "    # calculate the values of different parts in angular symmetry functions\n",
    "    diff_ijk = torch.einsum(\"ijk, ilk -> ijl\", diff_ij, diff_ik)\n",
    "    dist_prod = (dist_ij.unsqueeze(dim=-1) * dist_ik.unsqueeze(dim=-2))\n",
    "    \n",
    "    # handling situation that j = k\n",
    "    if j_elem == k_elem:\n",
    "        dist_prod = torch.triu(dist_prod, diagonal = 1)\n",
    "        \n",
    "    idx_i, idx_j, idx_k = torch.where(dist_prod) \n",
    "\n",
    "    part_1 = diff_ijk[idx_i, idx_j, idx_k] / dist_prod[idx_i, idx_j, idx_k]\n",
    "    part_1 = (part_1.unsqueeze(dim=1) * Lambda + 1) ** zeta\n",
    "\n",
    "    part_2 = torch.exp(-eta * (dist_ij[idx_i, idx_j] ** 2 + dist_ik[idx_i, idx_k] ** 2).unsqueeze(dim=-1))\n",
    "\n",
    "    pair_fc_ij = 0.5 * (torch.cos(torch.pi * dist_ij[idx_i, idx_j].unsqueeze(dim=-1) / R_c) + 1)\n",
    "    pair_fc_ik = 0.5 * (torch.cos(torch.pi * dist_ik[idx_i, idx_k].unsqueeze(dim=-1) / R_c) + 1)   \n",
    "    part_3 = pair_fc_ij * pair_fc_ik\n",
    "\n",
    "    sfs = torch.zeros((counts.shape[0], R_c.shape[0]), device=tensors['n_diff'].device)\n",
    "    sfs = sfs.index_add(0, idx_i, part_1 * part_2 * part_3 * 2 ** (1-zeta))\n",
    "    \n",
    "    return sfs\n",
    "\n",
    "def G4_SF(tensors, j_elem, k_elem, zeta, Lambda, eta, R_c):\n",
    "    zeta = zeta.to(device=tensors['n_diff'].device)\n",
    "    Lambda = Lambda.to(device=tensors['n_diff'].device)\n",
    "    eta = eta.to(device=tensors['n_diff'].device)\n",
    "    R_c = R_c.to(device=tensors['n_diff'].device)\n",
    "    diff = tensors['n_diff']\n",
    "    dist = tensors['n_dist']   \n",
    "    atom_i_idx = tensors['atom_i_idx']\n",
    "    counts = tensors['counts']\n",
    "    \n",
    "    j_mask = (tensors['j_elems'] == j_elem)\n",
    "    k_mask = (tensors['j_elems'] == k_elem)\n",
    "    \n",
    "    # get relative index of neighbors\n",
    "    atom_idx_j_masked, j_inv_idx, j_counts = torch.unique_consecutive(\n",
    "        atom_i_idx[j_mask], return_inverse=True, return_counts=True,\n",
    "    )\n",
    "    atom_idx_k_masked, k_inv_idx, k_counts = torch.unique_consecutive(\n",
    "        atom_i_idx[k_mask], return_inverse=True, return_counts=True,\n",
    "    )\n",
    "    \n",
    "    g_idx = torch.arange(j_inv_idx.shape[0], device=tensors['n_diff'].device)\n",
    "    idx_min, _ = scatter_min(g_idx, j_inv_idx)\n",
    "    j_ridx = g_idx - idx_min[j_inv_idx]\n",
    "\n",
    "    g_idx = torch.arange(k_inv_idx.shape[0], device=tensors['n_diff'].device)\n",
    "    idx_min, _ = scatter_min(g_idx, k_inv_idx)\n",
    "    k_ridx = g_idx - idx_min[k_inv_idx]\n",
    "    \n",
    "    # get the matrix of M * N * ..., \n",
    "    # where M is the number of center atoms, \n",
    "    # N is the maximum number of their j or k neighbors\n",
    "    diff_ij = torch.zeros((counts.shape[0], j_counts.max(), 3), device=tensors['n_diff'].device)\n",
    "    diff_ik = torch.zeros((counts.shape[0], k_counts.max(), 3), device=tensors['n_diff'].device)\n",
    "    dist_ij = torch.zeros((counts.shape[0], j_counts.max()), device=tensors['n_diff'].device)\n",
    "    dist_ik = torch.zeros((counts.shape[0], k_counts.max()), device=tensors['n_diff'].device)\n",
    "    \n",
    "    diff_ij[atom_i_idx[j_mask], j_ridx] = diff[j_mask]\n",
    "    diff_ik[atom_i_idx[k_mask], k_ridx] = diff[k_mask]\n",
    "    dist_ij[atom_i_idx[j_mask], j_ridx] = dist[j_mask]\n",
    "    dist_ik[atom_i_idx[k_mask], k_ridx] = dist[k_mask]\n",
    "    \n",
    "    # calculate the values of different parts in angular symmetry functions\n",
    "    diff_ijk = torch.einsum(\"ijk, ilk -> ijl\", diff_ij, diff_ik)\n",
    "    dist_prod = (dist_ij.unsqueeze(dim=-1) * dist_ik.unsqueeze(dim=-2))\n",
    "    \n",
    "    # handling situation that j = k\n",
    "    if j_elem == k_elem:\n",
    "        dist_prod = torch.triu(dist_prod, diagonal = 1)\n",
    "        \n",
    "    idx_i, idx_j, idx_k = torch.where(dist_prod)\n",
    "    pair_dist_jk = torch.norm(diff_ik[idx_i, idx_k] - diff_ij[idx_i, idx_j], dim=-1)\n",
    "    jk_mask = pair_dist_jk.unsqueeze(-1) < R_c[0]\n",
    "    \n",
    "    part_1 = diff_ijk[idx_i, idx_j, idx_k] / dist_prod[idx_i, idx_j, idx_k]\n",
    "    part_1 = (part_1.unsqueeze(dim=1) * Lambda + 1) ** zeta\n",
    "\n",
    "    part_2 = torch.exp(-eta * (dist_ij[idx_i, idx_j] ** 2 + dist_ik[idx_i, idx_k] ** 2).unsqueeze(dim=-1))\n",
    "\n",
    "    pair_fc_ij = 0.5 * (torch.cos(torch.pi * dist_ij[idx_i, idx_j].unsqueeze(dim=-1) / R_c) + 1)\n",
    "    pair_fc_ik = 0.5 * (torch.cos(torch.pi * dist_ik[idx_i, idx_k].unsqueeze(dim=-1) / R_c) + 1)  \n",
    "    pair_fc_jk = 0.5 * (torch.cos(torch.pi * pair_dist_jk.unsqueeze(dim=-1) / R_c) + 1)  \n",
    "    part_3 = pair_fc_ij * pair_fc_ik * pair_fc_jk\n",
    "\n",
    "    sfs = torch.zeros((counts.shape[0], R_c.shape[0]), device=tensors['n_diff'].device)\n",
    "    sfs = sfs.index_add(0, idx_i[jk_mask], (part_1 * part_2 * part_3 * 2 ** (1-zeta))[jk_mask])\n",
    "    \n",
    "    return sfs\n",
    "\n",
    "bp_sf_fns = {'G2': G2_SF, 'G3': G3_SF, 'G4': G4_SF, 'G5': G5_SF}\n",
    "class BPSymmFunc:\n",
    "    \"\"\"\n",
    "    Get Behler-Parrinello style symmetry function values of atoms\n",
    "    \"\"\"\n",
    "    def __init__(self, sf_spec):\n",
    "        self.sf_spec = defaultdict(list)\n",
    "        for elem, elem_spec in sf_spec.items():\n",
    "            for spec in elem_spec:\n",
    "                fn = bp_sf_fns[spec['type']]\n",
    "                options = {k:torch.FloatTensor(v)\n",
    "                           if isinstance(v, list) else v \n",
    "                           for k, v in spec.items() if k != 'type'}\n",
    "                self.sf_spec[elem].append((fn, options))\n",
    "    \n",
    "    def __call__(self, tensors):\n",
    "        fps = {}\n",
    "        for elem, elem_spec in self.sf_spec.items():    \n",
    "            sfs = []\n",
    "            i_elem = atomic_numbers[elem]\n",
    "            i_masked = self.get_i_masked(tensors, i_elem=i_elem)\n",
    "            for fn, options in elem_spec:\n",
    "                sf = fn(i_masked, **options)\n",
    "                sfs.append(sf)\n",
    "            sfs =  torch.hstack(sfs)\n",
    "            fps['{}_sfs'.format(elem)] = sfs\n",
    "            fps['{}_image_idx'.format(elem)] = i_masked['atom_image_idx']\n",
    "            \n",
    "        tensors['fps'] = fps\n",
    "        return tensors\n",
    "    \n",
    "    def get_i_masked(self, tensors, i_elem):\n",
    "        \"\"\"This function aims to construct M * N matrices, \n",
    "        where M is the number of selected center atoms,\n",
    "        N is the maximum number of these atoms' neighbors.\n",
    "        \"\"\"\n",
    "        i_mask = (tensors['i_elems'] == i_elem)\n",
    "        pair_image_idx = tensors['pair_image_idx']\n",
    "        pair_i_idx = tensors['pair_i_idx']\n",
    "        atom_image_idx = tensors['atom_image_idx'][tensors['elems'] == i_elem]\n",
    "        numbers = tensors['numbers']\n",
    "        _, inverse_indices, counts = torch.unique_consecutive(pair_i_idx[i_mask],\n",
    "                                                              return_inverse=True,\n",
    "                                                              return_counts=True)\n",
    "    \n",
    "        i_masked = {\n",
    "            'atom_image_idx': atom_image_idx,\n",
    "            'atom_i_idx': inverse_indices,             # atom indices of i masked pairs in this batch           \n",
    "            'n_dist': tensors['n_dist'][i_mask],       # distances of i masked pairs\n",
    "            'n_diff': tensors['n_diff'][i_mask],       # distance vectors of i masked pairs\n",
    "            'counts': counts,                          # how many pairs there are for each i atom\n",
    "            'j_elems': tensors['j_elems'][i_mask],     # j elements of pairs\n",
    "        }\n",
    "        return i_masked\n",
    "\n",
    "class BPNNP(nn.Module):\n",
    "    def __init__(self, sf_spec, layer_size: list, cutoff, scale=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.preprocess = BatchNeighborList(cutoff)\n",
    "        self.sf_spec = sf_spec\n",
    "        self.fingerprint = BPSymmFunc(self.sf_spec)\n",
    "        self.elems_num = len(self.sf_spec)\n",
    "        hidden_layers = [nn.Sequential(nn.Linear(layer_size[i],\n",
    "                                                 layer_size[i+1]),\n",
    "                                       nn.BatchNorm1d(layer_size[i+1]),   # batch normalization\n",
    "                                       nn.Sigmoid(),\n",
    "                                      )\n",
    "                         for i in range(len(layer_size) - 1)]\n",
    "        self.elem_layers = {}\n",
    "        for elem, elem_specs in self.sf_spec.items():\n",
    "            input_size = 0\n",
    "            for spec in elem_specs:\n",
    "                input_size += len(spec['R_c'])\n",
    "                \n",
    "            input_layer = nn.Sequential(nn.Linear(input_size, layer_size[0]),  \n",
    "                                        nn.BatchNorm1d(layer_size[0]),     # batch normalization\n",
    "                                        nn.Sigmoid(),\n",
    "                                       )    \n",
    "            output_layer = nn.Linear(layer_size[-1], 1)\n",
    "            layers = [input_layer] + hidden_layers + [output_layer]\n",
    "            self.elem_layers[elem] = nn.ModuleList(layers)\n",
    "        self.elem_layers = nn.ModuleDict(self.elem_layers)\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, tensors):\n",
    "        \"\"\"The input is a dict of tensors, which is directed obtained from Dataset \n",
    "        with n_indices, n_diff, and n_dist keys\"\"\"\n",
    "        tensors = self.preprocess(tensors)\n",
    "        tensors = self.fingerprint(tensors)\n",
    "        energy = []\n",
    "        image_idx = []\n",
    "        for k, layers in self.elem_layers.items():\n",
    "            x = tensors['fps'][k + '_sfs']\n",
    "            for layer in layers:\n",
    "                x = layer(x)\n",
    "                \n",
    "            energy.append(x)\n",
    "            image_idx.append(tensors['fps'][k + '_image_idx'])\n",
    "        \n",
    "        energy = torch.cat(energy).squeeze(dim=-1)\n",
    "        image_idx = torch.cat(image_idx)\n",
    "        dE_dxyz = torch.autograd.grad(\n",
    "            energy,\n",
    "            tensors['coord'],\n",
    "            grad_outputs=torch.ones_like(energy),\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "        energy = scatter_add(energy, image_idx)\n",
    "        result_dict = {'energy': energy}\n",
    "        forces = -dE_dxyz       \n",
    "        result_dict['forces'] = forces\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407f8fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import re, os, logging, json, time, argparse\n",
    "\n",
    "from ase.data import atomic_numbers\n",
    "from ase.db import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506169ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset):\n",
    "    datalen = len(dataset)\n",
    "    num_validation = int(math.ceil(datalen * 0.10))\n",
    "    indices = np.random.permutation(len(dataset))\n",
    "    splits = {\n",
    "        \"train\": indices[num_validation:].tolist(),\n",
    "        \"validation\": indices[:num_validation].tolist(),\n",
    "    }\n",
    "\n",
    "    with open(\"datasplits.json\", \"w\") as f:\n",
    "        json.dump(splits, f)\n",
    "\n",
    "    # Split the dataset\n",
    "    datasplits = {}\n",
    "    for key, indices in splits.items():\n",
    "        datasplits[key] = torch.utils.data.Subset(dataset, indices)\n",
    "    return datasplits\n",
    "\n",
    "n2p2_sf_type = {'2': 'G2', '3': 'G4', '9': 'G5'}\n",
    "def get_sf_dict(input_file = 'input.nn'):\n",
    "    \"\"\" Read symmetry functions parameters from input.nn \"\"\"\n",
    "    lines = []\n",
    "    for line in open(input_file, 'r'):\n",
    "        if line.startswith('symfunc'):\n",
    "            lines.append(line.strip())\n",
    "    sf_specs = {}\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if re.match('[a-zA-Z]', line[4]):\n",
    "            try:\n",
    "                sf_specs[\" \".join(line[1:5])]\n",
    "            except:\n",
    "                sf_specs[\" \".join(line[1:5])] = {'eta': [], 'Lambda': [], 'zeta': [], 'R_c': []}\n",
    "            finally:\n",
    "                sf_specs[\" \".join(line[1:5])]['eta'].append(float(line[5]))\n",
    "                sf_specs[\" \".join(line[1:5])]['Lambda'].append(float(line[6]))\n",
    "                sf_specs[\" \".join(line[1:5])]['zeta'].append(float(line[7]))\n",
    "                sf_specs[\" \".join(line[1:5])]['R_c'].append(float(line[8]))\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                sf_specs[\" \".join(line[1:4])]\n",
    "            except:\n",
    "                sf_specs[\" \".join(line[1:4])] = {'eta': [], 'R_s': [], 'R_c': []}\n",
    "            finally:\n",
    "                sf_specs[\" \".join(line[1:4])]['eta'].append(float(line[4]))\n",
    "                sf_specs[\" \".join(line[1:4])]['R_s'].append(float(line[5]))\n",
    "                sf_specs[\" \".join(line[1:4])]['R_c'].append(float(line[6]))\n",
    "\n",
    "    new_sf_specs = {}\n",
    "    for k1, v1 in sf_specs.items():\n",
    "        sf_type = k1.split()\n",
    "        sf_dict = {'type': n2p2_sf_type[sf_type[1]], 'j_elem': atomic_numbers[sf_type[2]]}\n",
    "        sf_dict.update({k2: v2 for k2, v2 in v1.items()})\n",
    "        if len(sf_type) == 4:\n",
    "            sf_dict.update({'k_elem': atomic_numbers[sf_type[3]]})\n",
    "        try:\n",
    "            new_sf_specs[sf_type[0]]\n",
    "        except:\n",
    "            new_sf_specs[sf_type[0]] = []\n",
    "        finally:\n",
    "            new_sf_specs[sf_type[0]].append(sf_dict)\n",
    "            \n",
    "    return new_sf_specs\n",
    "\n",
    "def forces_criterion(predicted, target, reduction=\"mean\"):\n",
    "    # predicted, target are (bs, max_nodes, 3) tensors\n",
    "    # node_count is (bs) tensor\n",
    "    diff = predicted - target\n",
    "    total_squared_norm = torch.norm(diff, dim=1)  # bs\n",
    "    if reduction == \"mean\":\n",
    "        scalar = torch.mean(total_squared_norm)\n",
    "    elif reduction == \"sum\":\n",
    "        scalar = torch.sum(total_squared_norm)\n",
    "    else:\n",
    "        raise ValueError(\"Reduction must be 'mean' or 'sum'\")\n",
    "    return scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99ff11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset and split data\n",
    "db = connect('../Au-water/dft_structures.db')\n",
    "dataset = AseDataset(db, cutoff=6.0)\n",
    "datasplits = split_data(dataset=dataset)\n",
    "\n",
    "# Setup loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasplits[\"train\"],\n",
    "    batch_size=32,\n",
    "    sampler=torch.utils.data.RandomSampler(datasplits[\"train\"]),\n",
    "    collate_fn=collate_atomsdata,\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasplits[\"validation\"], \n",
    "    batch_size=32, \n",
    "    collate_fn=collate_atomsdata,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6011b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "sf_specs = get_sf_dict('../Au-water/input.nn')\n",
    "net = BPNNP(sf_specs, layer_size=[30, 30], cutoff=6.0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "# Setup optimizer\n",
    "initial_lr = 0.0001    # learning rate\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=initial_lr)\n",
    "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
    "scheduler_fn = lambda step: 0.96 ** (step / 100000)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, scheduler_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 22.15797758102417, Step: 10, total loss: 882302.3125, energy loss: 8787228.0, forces loss: 3977.2216796875\n",
      "Time cost: 23.182730436325073, Step: 20, total loss: 870756.75, energy loss: 8671648.0, forces loss: 3991.0517578125\n",
      "Time cost: 22.752806901931763, Step: 30, total loss: 868229.9375, energy loss: 8647994.0, forces loss: 3811.635986328125\n",
      "Time cost: 22.49624252319336, Step: 40, total loss: 854696.625, energy loss: 8511713.0, forces loss: 3917.041748046875\n",
      "Time cost: 22.27514410018921, Step: 50, total loss: 846562.625, energy loss: 8430275.0, forces loss: 3927.89501953125\n",
      "Time cost: 22.419592142105103, Step: 60, total loss: 837650.875, energy loss: 8341916.0, forces loss: 3843.635009765625\n",
      "Time cost: 22.335995197296143, Step: 70, total loss: 830876.0, energy loss: 8272587.5, forces loss: 4019.1435546875\n",
      "Time cost: 22.24176049232483, Step: 80, total loss: 824064.375, energy loss: 8204930.0, forces loss: 3968.214111328125\n",
      "Time cost: 22.114821672439575, Step: 90, total loss: 812927.375, energy loss: 8093701.0, forces loss: 3952.4794921875\n",
      "Time cost: 22.280303716659546, Step: 100, total loss: 813280.5625, energy loss: 8098541.0, forces loss: 3807.1748046875\n",
      "Time cost: 21.572155475616455, Step: 110, total loss: 806795.5, energy loss: 8033009.0, forces loss: 3882.860107421875\n",
      "Time cost: 21.84428071975708, Step: 120, total loss: 794559.0, energy loss: 7909299.5, forces loss: 4032.27685546875\n",
      "Time cost: 22.14816641807556, Step: 130, total loss: 790395.0625, energy loss: 7868835.0, forces loss: 3901.74755859375\n",
      "Time cost: 21.844398498535156, Step: 140, total loss: 783087.8125, energy loss: 7795577.5, forces loss: 3922.323486328125\n",
      "Time cost: 21.669975996017456, Step: 150, total loss: 776622.875, energy loss: 7730981.5, forces loss: 3916.3271484375\n",
      "Time cost: 21.942731618881226, Step: 160, total loss: 767041.625, energy loss: 7635384.0, forces loss: 3892.45458984375\n",
      "Time cost: 21.441705226898193, Step: 170, total loss: 760803.5625, energy loss: 7572937.0, forces loss: 3899.850830078125\n"
     ]
    }
   ],
   "source": [
    "forces_weight=0.90\n",
    "step = 0\n",
    "start = time.time()\n",
    "epoch = 100\n",
    "for i in range(epoch):\n",
    "    for device_batch in train_loader:    \n",
    "        batch = {\n",
    "                k: v.to(device=device, non_blocking=True)\n",
    "                for (k, v) in device_batch.items()\n",
    "        }\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward, backward and optimize\n",
    "        outputs = net(batch)\n",
    "        energy_loss = criterion(outputs[\"energy\"], batch[\"energy\"])\n",
    "        if forces_weight:\n",
    "            forces_loss = forces_criterion(outputs[\"forces\"], batch[\"forces\"], reduction=\"sum\")\n",
    "        else:\n",
    "            forces_loss = 0.0\n",
    "        total_loss = (\n",
    "            forces_weight * forces_loss\n",
    "            + (1 - forces_weight) * energy_loss\n",
    "        )\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        if (step % 10 == 0): \n",
    "            end = time.time()\n",
    "            cost = end - start\n",
    "            start = time.time()\n",
    "            print(\"Time cost: {}, Step: {}, total loss: {}, energy loss: {}, forces loss: {}\".format(cost, step, total_loss, energy_loss, forces_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24775164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
